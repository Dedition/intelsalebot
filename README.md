# SalesBot

SalesBot is a chatbot designed to assist customers with their purchase inquiries. It is built using the Python programming language and various machine learning libraries. It will be a long-term project that will be updated that will be useful for both customers and sales representatives.

## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes.

### Prerequisites

You will need to have Python and pip installed on your machine. You can download Python [here](https://www.python.org/downloads/) and [pip](https://pip.pypa.io/en/stable/installing/) here.

In addition, you will need to install the following libraries:

nltk
tensorflow
keras
numpy
json
pickle

You can install these libraries by running the following command:

```
pip install nltk tensorflow keras numpy json pickle
```

## Running the code

1. Clone the repository to your local machine

 ```
git clone <https://github.com/<username>/SalesBot.git>
```

2. Navigate to the aibot directory

```
cd SalesBot
```

3. Run the chatbot

```
python chatbot.py
```

The chatbot should now be running and ready to assist customers with their purchase inquiries.

## Built With

• [Python](https://www.python.org/) - The programming language used

• [nltk](https://www.nltk.org/) - Natural Language Toolkit library

• [tensorflow](https://www.tensorflow.org/) - Machine learning library

• [keras](https://keras.io/) - High-level neural networks API

• [numpy](https://numpy.org/) - Scientific computing library

• [json](https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Objects/JSON) - JSON library

• [pickle](https://docs.python.org/3/library/pickle.html) - Pickling library

## Authors

[Dedition](https://github.com/Dedition) - Leo Ladipo

## Acknowledgments

Thanks to the team at OpenAI for providing the GPT-3 model to generate the code.

Thanks to the team at TensorFlow and Keras for providing the machine learning libraries used in this project.

Thanks to the team at NLTK for providing the natural language processing library used in this project.
